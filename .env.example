# MySQL Database Configuration
# Copy this file to .env and fill in your actual credentials
# The .env file will be ignored by git to keep credentials secure

MYSQL_HOST=localhost
MYSQL_PORT=3306
MYSQL_USER=root
MYSQL_PASSWORD=your_password_here
MYSQL_DATABASE=your_database_name

# MongoDB Database Configuration
MONGODB_URI=mongodb://localhost:27017
MONGODB_DATABASE=your_database_name

# LLM Configuration
# Provider selection: anthropic, openai, google
# Use 'openai' for local LLMs (LM Studio, Ollama, vLLM)
LLM_PROVIDER=anthropic

# Anthropic Configuration
ANTHROPIC_API_KEY=your_anthropic_api_key_here
ANTHROPIC_MODEL=claude-sonnet-4-5-20250929

# OpenAI Configuration (optional - requires: uv sync --group llm-openai)
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-4o

# Local LLM Configuration (LM Studio, Ollama, vLLM, etc.)
# To use local LLMs, set LLM_PROVIDER=openai and configure:
# OPENAI_BASE_URL=http://localhost:1234/v1  # LM Studio default port
# OPENAI_MODEL=your-local-model-name
# (OPENAI_API_KEY is not required when OPENAI_BASE_URL is set)

# Google Configuration (optional - requires: uv sync --group llm-google)
GOOGLE_API_KEY=your_google_api_key_here
GOOGLE_MODEL=gemini-2.5-flash

# LLM Batch Mode
# Enable async batch API for large analysis runs
# When enabled, prompts are submitted in bulk; use `wct poll` to check status
# WAIVERN_LLM_BATCH_MODE=true

# Artifact Store Configuration
# Backend type: memory (default), filesystem, remote
WAIVERN_STORE_TYPE=memory

# Filesystem backend configuration
# Base path for storing artifacts (default: .waivern)
# WAIVERN_STORE_PATH=.waivern

# Remote backend configuration (future - not yet implemented)
# WAIVERN_STORE_URL=https://your-remote-store-url
# WAIVERN_STORE_API_KEY=your_remote_store_api_key
